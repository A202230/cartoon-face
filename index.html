<script>
let audioContext, analyser, dataArray;

document.getElementById("startBtn").onclick = async () => {
  console.log("Start clicked");

  if (typeof DeviceMotionEvent.requestPermission === "function") {
    await DeviceMotionEvent.requestPermission();
  }

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  audioContext = new AudioContext();
  const source = audioContext.createMediaStreamSource(stream);
  analyser = audioContext.createAnalyser();
  analyser.fftSize = 256;
  dataArray = new Uint8Array(analyser.frequencyBinCount);
  source.connect(analyser);

  window.addEventListener("deviceorientation", updateEyes);
  requestAnimationFrame(updateCore);

  console.log("Everything started");
};

/* --- TEST SPEECH BUTTON --- */
const speakTest = document.createElement("button");
speakTest.innerText = "Speak Test";
speakTest.style.position = "absolute";
speakTest.style.bottom = "100px";
speakTest.style.left = "50%";
speakTest.style.transform = "translateX(-50%)";
speakTest.style.padding = "15px 25px";
speakTest.style.fontSize = "20px";
document.body.appendChild(speakTest);

speakTest.onclick = () => {
  console.log("Speakingâ€¦");
  const msg = new SpeechSynthesisUtterance("Hello Andrew, this is a test.");
  speechSynthesis.speak(msg);
};

/* --- MOTION LOOP --- */
function updateEyes(e) {
  let tiltX = e.gamma * 1.5;
  let tiltY = e.beta * 1.0;

  document.getElementById("pupilL").style.transform =
    `translate(${tiltX}px, ${tiltY}px)`;
  document.getElementById("pupilR").style.transform =
    `translate(${tiltX}px, ${tiltY}px)`;
}

/* --- SOUND LOOP --- */
function updateCore() {
  analyser.getByteFrequencyData(dataArray);
  let volume = dataArray.reduce((a,b)=>a+b) / dataArray.length;

  let scale = 1 + volume / 30;
  let core = document.getElementById("core");
  core.style.transform = `translateX(-50%) scale(${scale})`;
  core.style.opacity = 0.3 + (volume / 120);

  requestAnimationFrame(updateCore);
}
</script>
